# ğŸ” RAG Chatbot using LangChain + Gemini + Chroma

This project is a **Retrieval-Augmented Generation (RAG) chatbot** built using **LangChain**, **Gemini Pro (Google's LLM)**, and **ChromaDB**. The chatbot takes any website URL, scrapes and preprocesses the content, converts it into vector embeddings, and then answers questions with rich, context-aware responses.

## ğŸš€ Features

- ğŸŒ **Dynamic Website Scraping**: Enter any article or blog URL â€” the chatbot fetches and processes the content in real time.
- ğŸ§  **Contextual Q&A with Gemini**: Uses Google's Gemini model to generate intelligent answers based on retrieved context chunks.
- âš¡ **Fast Semantic Search**: ChromaDB is used to store and retrieve vectorized document chunks using Sentence Transformers.
- ğŸ’¬ **Interactive Chat Interface**: Engage with the chatbot directly via a command-line chat loop or a Colab widget interface.

---

## ğŸ› ï¸ Tech Stack

- **ğŸ§  LLM**: Google Gemini Pro (`gemini-1.5-flash`)
- **ğŸ”— Framework**: LangChain
- **ğŸ“¦ Vector Store**: ChromaDB
- **ğŸ§¬ Embeddings**: `sentence-transformers/all-MiniLM-L6-v2`
- **ğŸ” Web Scraping**: BeautifulSoup
- **ğŸ’¡ Environment**: Google Colab / Jupyter Notebook / Local Python

---

## ğŸ“¦ Installation

```bash
pip install langchain langchain-community sentence-transformers chromadb google-generativeai bs4
